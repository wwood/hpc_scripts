#!/usr/bin/env python3
"""Interactive job viewer similar to ``htop``.

This tool combines running and recently finished jobs into a single table
and allows selecting rows to inspect job logs.
"""

import argparse
import importlib.util
import os
import re
import subprocess
import sys
import time
import unicodedata
import textwrap
import json
import getpass
import shutil
import threading
from datetime import datetime, timedelta
from importlib.machinery import SourceFileLoader

import curses


def _load_script(name):
    """Load a script from ``bin`` as a module."""

    path = os.path.join(os.path.dirname(__file__), name)
    loader = SourceFileLoader(f"{name}_module", path)
    spec = importlib.util.spec_from_loader(f"{name}_module", loader)
    mod = importlib.util.module_from_spec(spec)
    loader.exec_module(mod)
    return mod


mqstat = _load_script("mqstat")
mqsub = _load_script("mqsub")


ansi_re = re.compile(r"\x1b\[(\d+)m(.*?)\x1b\[0m")
# basic ANSI colour escapes used for row colouring
ORANGE = "\033[33m"

# Automatically refresh the job table every 10 minutes (in seconds)
REFRESH_INTERVAL = 10 * 60

# Maximum number of jobs to display. If more jobs are found, the list is
# truncated and the user is notified.
MAX_JOBS = 1000


def _parse_time(val: str | None) -> int | None:
    """Parse PBS time strings into Unix timestamps."""
    if not val:
        return None
    try:
        dt = datetime.strptime(val.strip(), "%a %b %d %H:%M:%S %Y")
        return int(dt.timestamp())
    except ValueError:
        return None


def _parse_hms(val: str | None) -> int:
    """Convert ``HH:MM:SS`` strings to seconds."""
    if not val:
        return 0
    parts = [int(p) for p in val.split(":")]
    while len(parts) < 3:
        parts.insert(0, 0)
    h, m, s = parts[-3:]
    return h * 3600 + m * 60 + s


_mem_re = re.compile(r"(\d+)([a-zA-Z]+)")


def _mem_to_gb(val: str | None) -> float:
    if not val:
        return 0.0
    m = _mem_re.match(str(val))
    if not m:
        return 0.0
    num = int(m.group(1))
    unit = m.group(2).lower()
    if unit == "gb":
        return float(num)
    if unit == "mb":
        return num / 1024.0
    if unit == "kb":
        return num / (1024.0 * 1024)
    if unit == "b":
        return num / (1024.0 * 1024 * 1024)
    return 0.0


def _mem_to_kb(val: str | None) -> int:
    if not val:
        return 0
    m = _mem_re.match(str(val))
    if not m:
        return 0
    num = int(m.group(1))
    unit = m.group(2).lower()
    if unit == "kb":
        return num
    if unit == "mb":
        return num * 1024
    if unit == "gb":
        return num * 1024 * 1024
    if unit == "b":
        return num // 1024
    return 0


def _parse_job(obj: dict) -> dict:
    """Convert raw JSON job info into the format used by ``mqtop``."""
    job = {"id": obj.get("id"), "queue": obj.get("queue"), "state": obj.get("job_state")}
    job["name"] = obj.get("Job_Name")
    job["user"] = obj.get("euser") or obj.get("Job_Owner", "").split("@")[0]
    job["qtime"] = _parse_time(obj.get("qtime"))
    job["start_time"] = _parse_time(obj.get("stime"))
    job["obittime"] = _parse_time(obj.get("obittime"))
    job["mtime"] = _parse_time(obj.get("mtime"))
    rl = obj.get("Resource_List", {}) or {}
    job["ncpus"] = int(rl.get("ncpus", 0) or 0)
    job["ngpus"] = int(rl.get("ngpus", 0) or 0)
    job["mem_request_gb"] = _mem_to_gb(rl.get("mem"))
    wt = rl.get("walltime")
    if wt:
        job["walltime_total"] = _parse_hms(wt)
        job["walltime"] = job["walltime_total"]
    ru = obj.get("resources_used", {}) or {}
    job["cpupercent"] = int(ru.get("cpupercent", 0) or 0)
    job["ncpus_used"] = int(ru.get("ncpus", 0) or 0)
    job["mem_usage"] = _mem_to_kb(ru.get("mem"))
    job["vmem_used_kb"] = _mem_to_kb(ru.get("vmem"))
    job["walltime_used"] = _parse_hms(ru.get("walltime"))
    if "walltime_total" in job and job["walltime_used"]:
        job["walltime"] = job["walltime_total"] - job["walltime_used"]
    job["cput_used"] = _parse_hms(ru.get("cput"))
    if "Exit_status" in obj:
        try:
            job["exit_status"] = int(obj["Exit_status"])
        except Exception:
            pass
    return job


def _load_jobs_from_json(path: str, user: str, source: str) -> list[dict]:
    """Load jobs for *user* from a qstat JSON file.

    Parameters
    ----------
    path:
        Path to the JSON file to load.
    user:
        User whose jobs should be returned.
    source:
        String describing the origin of the data (``qstat.json`` or
        ``qstatx.json``). This value is attached to each returned job via the
        ``source`` key.
    """
    if not path or not os.path.exists(path):
        return []
    jobs: list[dict] = []

    repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    rust_bin = os.path.join(
        repo_root, "qstat_filter", "target", "release", "qstat_filter"
    )

    proc = None
    if os.path.exists(rust_bin):
        try:
            proc = subprocess.run(
                [rust_bin, path, user], text=True, capture_output=True
            )
        except Exception:
            proc = None
    if proc and proc.returncode == 0 and proc.stdout.strip():
        for line in proc.stdout.splitlines():
            try:
                job = _parse_job(json.loads(line))
                job["source"] = source
                jobs.append(job)
            except Exception:
                continue
        return jobs

    try:
        with open(path) as fh:
            data = json.load(fh)
    except Exception:
        return []
    for jid, info in (data.get("Jobs") or {}).items():
        if info.get("euser") != user:
            continue
        info = dict(info)
        info["id"] = jid
        job = _parse_job(info)
        job["source"] = source
        jobs.append(job)
    return jobs


def _fetch_job(job_id: str, user: str) -> dict | None:
    """Return job info for *job_id* using ``qstat -f``."""
    try:
        proc = subprocess.run(
            ["qstat", "-f", "-F", "json", str(job_id)],
            text=True,
            capture_output=True,
        )
    except FileNotFoundError:
        return None
    if proc.returncode != 0 or not proc.stdout.strip():
        return None
    try:
        data = json.loads(proc.stdout)
        jid, info = next(iter(data.get("Jobs", {}).items()))
        info["id"] = jid
        if info.get("euser") and info["euser"] != user:
            return None
        return _parse_job(info)
    except Exception:
        return None


def _recent_finished_jobs(user: str, existing: set[str]) -> tuple[list[dict], int, int]:
    """Fetch recently finished jobs not yet in history.

    Returns a tuple ``(jobs, total, updated)`` where ``total`` is the number of
    job IDs reported by ``qselect`` and ``updated`` is the number of jobs for
    which we successfully fetched details via ``qstat -f``.
    """
    cutoff = (datetime.now() - timedelta(minutes=10)).strftime("%m%d%H%M")
    try:
        proc = subprocess.run(
            ["qselect", "-u", user, f"-te.gt.{cutoff}"],
            text=True,
            capture_output=True,
        )
    except FileNotFoundError:
        return [], 0, 0
    ids = proc.stdout.split()
    jobs = []
    for jid in ids:
        if jid in existing:
            continue
        info = _fetch_job(jid, user)
        if info:
            info["source"] = "qselect/qstat -f"
            jobs.append(info)
    return jobs, len(ids), len(jobs)


def _load_history(qstatx_path: str, user: str, existing: set[str]) -> dict[str, dict]:
    """Return finished jobs from qstatx and recent ``qselect`` results."""

    finished: dict[str, dict] = {}
    hist = _load_jobs_from_json(qstatx_path, user, "qstatx.json")
    for job in hist:
        if job["id"] in existing:
            continue
        finished[job["id"]] = job
    existing = set(existing) | set(finished)
    recent, total, updated_count = _recent_finished_jobs(user, existing)
    if total:
        print(
            f"qselect detected {total} jobs; updated {updated_count}",
            file=sys.stderr,
        )
    for job in recent:
        finished.setdefault(job["id"], job)
    return finished


def _start_history_loader(qstatx_path: str, user: str, existing: set[str]):
    """Start a background thread to load job history."""

    result: dict[str, dict] = {}

    def runner():
        result.update(_load_history(qstatx_path, user, set(existing)))

    thread = threading.Thread(target=runner, daemon=True)
    thread.start()
    return thread, result


def grafana_url(job_id: str) -> str:
    """Return Grafana dashboard URL for *job_id*.

    ``job_id`` may include a suffix such as ``.aqua`` which will be
    stripped before constructing the URL.
    """

    numeric = str(job_id).split(".")[0]
    return (
        "https://hpc-monitoring.eres.qut.edu.au/d/pbs-public-job/pbs-job?var-jobid="
        + numeric
    )


def _view_log_command(job: dict, which: str, user: str) -> tuple[str | list[str] | None, bool]:
    """Return a command to view a job's stdout or stderr.

    Parameters
    ----------
    job:
        Job dictionary as produced by :func:`_parse_job`.
    which:
        ``"o"`` for stdout or ``"e"`` for stderr.
    user:
        Username for ``qstat -f`` queries.

    Returns
    -------
    (cmd, shell):
        ``cmd`` is either a list of arguments or a shell command string. ``shell``
        indicates whether ``cmd`` should be executed via ``shell=True``.
    """

    suffix = "ER" if which == "e" else "OU"
    state = job.get("state")
    if state == "R":
        info = _fetch_job(job["id"], user)
        if not info or info.get("state") != "R":
            if info:
                job.update(info)
            state = job.get("state")
    if state in ("C", "F"):
        try:
            stdout_path, stderr_path = mqsub.PbsJobInfo.stdout_and_stderr_paths(job["id"])
        except Exception:
            stdout_path = stderr_path = None
        path = stderr_path if which == "e" else stdout_path
        if path and os.path.isdir(path):
            path = os.path.join(path, f"{job['id']}.{suffix}")
        if path and os.path.exists(path):
            return ["less", path], False
    elif state == "R":
        cmd = (
            f"/pkg/hpc/scripts/ssh-to-job {job['id']} cat /var/spool/PBS/spool/{job['id']}.{suffix} | less"
        )
        return cmd, True
    return None, False


def refresh_due(last_refresh: float, now: float | None = None, interval: int = REFRESH_INTERVAL) -> bool:
    """Return ``True`` if a refresh should occur.

    Parameters
    ----------
    last_refresh:
        Timestamp of the most recent refresh.
    now:
        Current timestamp. Defaults to ``time.time()``.
    interval:
        Refresh interval in seconds. Defaults to :data:`REFRESH_INTERVAL`.
    """

    if now is None:
        now = time.time()
    return now - last_refresh >= interval


def strip_ansi(text: str) -> str:
    """Return *text* with ANSI colour escapes removed."""

    return ansi_re.sub(r"\2", text)


def visible_len(text: str) -> int:
    """Display width of *text* ignoring ANSI colour escapes."""

    return sum(_width(ch) for ch in strip_ansi(text))


def ljust_ansi(text: str, width: int) -> str:
    pad = max(width - visible_len(text), 0)
    return text + " " * pad


def rjust_ansi(text: str, width: int) -> str:
    pad = max(width - visible_len(text), 0)
    return " " * pad + text


def _width(ch):
    if unicodedata.combining(ch):
        return 0
    return 2 if unicodedata.east_asian_width(ch) in ("F", "W") else 1


def addstr_safe(stdscr, y, x, text, maxx, attr=0):
    width = 0
    out = []
    for ch in text:
        w = _width(ch)
        if x + width + w > maxx - 1:
            break
        out.append(ch)
        width += w
    if out:
        try:
            stdscr.addstr(y, x, "".join(out), attr)
        except curses.error:
            pass
    return width


def _addstr_offset(stdscr, y, text, x, x_offset, maxx, attr):
    for ch in text:
        w = _width(ch)
        if x + w <= x_offset:
            x += w
            continue
        if x - x_offset >= maxx - 1:
            break
        try:
            stdscr.addstr(y, x - x_offset, ch, attr)
        except curses.error:
            pass
        x += w
    return x


def draw_line(stdscr, y, line, maxx, highlight=False, x_offset=0):
    """Draw a line that may contain ANSI colour escape codes."""

    x = 0
    last = 0
    attr = curses.A_REVERSE if highlight else 0
    for match in ansi_re.finditer(line):
        x = _addstr_offset(stdscr, y, line[last:match.start()], x, x_offset, maxx, attr)
        colour = match.group(1)
        pair = {"92": 1, "91": 2, "93": 3, "33": 4}.get(colour, 0)
        colour_pair = curses.color_pair(pair)
        x = _addstr_offset(stdscr, y, match.group(2), x, x_offset, maxx, colour_pair | attr)
        last = match.end()
        if x - x_offset >= maxx - 1:
            break
    if x - x_offset < maxx - 1 and last < len(line):
        _addstr_offset(stdscr, y, line[last:], x, x_offset, maxx, attr)


HELP_TEXT = textwrap.dedent(
    """
    mqtop key bindings:
      q           quit
      h           show this help
      /           search jobs by name or id
      o           view stdout
      e           view stderr
      f           show full qstat info
      s           ssh to running job
      r           refresh
      u           toggle queued jobs
      g           open Grafana dashboard
      up/down     move selection
      left/right  scroll columns
      PgUp/PgDn   page
      k           kill selected job (qdel)

    Colours:
      Row colours indicate job state:
        - yellow: queued (state Q)
        - green: finished successfully (exit status 0)
        - red:   finished with error (non-zero exit status)
        - orange: other non-running states (e.g. hold/suspended)

      Field colours highlight low utilisation in running/finished jobs:
        - red cpu%: <10% CPU utilisation (and job ran >2 minutes)
        - red ram%: <10% RAM utilisation (and job ran >2 minutes)

      Notes column:
        - short: job ran for <60 seconds
        - !prefix: job exited with non-zero status
    """
).splitlines()


def show_help(stdscr):
    stdscr.nodelay(False)
    top = 0
    while True:
        maxy, maxx = stdscr.getmaxyx()
        stdscr.erase()
        for idx, line in enumerate(HELP_TEXT[top : top + maxy - 1]):
            addstr_safe(stdscr, idx, 0, line, maxx)
        addstr_safe(
            stdscr,
            maxy - 1,
            0,
            "q to exit help",
            maxx,
            curses.A_REVERSE,
        )
        stdscr.refresh()
        key = stdscr.getch()
        if key in (ord("q"), ord("h")):
            break
        elif key in (curses.KEY_DOWN,):
            if top < max(0, len(HELP_TEXT) - (maxy - 1)):
                top += 1
        elif key in (curses.KEY_UP,):
            if top > 0:
                top -= 1
        elif key == curses.KEY_NPAGE:
            top = min(len(HELP_TEXT) - (maxy - 1), top + (maxy - 1))
        elif key == curses.KEY_PPAGE:
            top = max(0, top - (maxy - 1))
    stdscr.nodelay(True)
    stdscr.clear()
    curses.curs_set(0)


def format_jobs(jobs, maxx, now=None):
    """Return formatted job table lines and corresponding job objects."""

    if now is None:
        now = time.time()

    rows = []
    headers = [
        "job_id",
        "name",
        "time used",
        "progress",
        "walltime",
        "waited",
        "age",
        "CPU",
        "cpu%",
        "RAM(G)",
        "ram%",
        "state",
        "queue",
        "note",
        "source",
    ]

    for job in jobs:
        if job.get("queue") == "cpu_inter_exec":
            continue
        queue = job.get("queue", "").replace("_batch_exec", "")
        job_id = str(job.get("id", "")).replace(".aqua", "")
        name = job.get("name", "")
        if name.startswith("snakejob"):
            name = "🐍" + name[len("snakejob") :]
        used_s = job.get("walltime_used", 0)
        total_s = job.get("walltime_total", job.get("walltime", 0))
        used = mqstat.format_hm(used_s)
        total = mqstat.format_hm(total_s)
        bar = mqstat.progress_bar(used_s, total_s)
        waited = ""
        qtime = job.get("qtime")
        start_time = job.get("start_time")
        state = job.get("state", "")
        if state == "Q" and qtime:
            waited = mqstat.format_hm(max(0, now - qtime))
        elif qtime and start_time:
            waited = mqstat.format_hm(max(0, start_time - qtime))

        age = ""
        if state in ("C", "F"):
            ft = job.get("obittime") or job.get("mtime")
            if ft:
                age = mqstat.format_hm(max(0, int(now - ft)))

        cpu = job.get("ncpus", 0)
        cpupercent = job.get("cpupercent")
        ncpus_used = job.get("ncpus_used", cpu)
        cpu_util = 0
        if job.get("state") in ("C", "F"):
            cput_used = job.get("cput_used", 0)
            if used_s and cpu:
                cpu_util = cput_used / (used_s * cpu) * 100
        elif cpupercent is not None and ncpus_used:
            cpu_util = cpupercent / ncpus_used
        cpu_util_str = f"{int(cpu_util)}%" if cpu_util else ""
        cpu_low = cpu_util and cpu_util < 10
        short_run = used_s <= 120

        ram = int(job.get("mem_request_gb", 0))
        vmem_kb = job.get("vmem_used_kb") or job.get("mem_usage", 0)
        ram_util = (vmem_kb / (ram * 1024 * 1024) * 100) if ram else 0
        ram_util_str = f"{int(ram_util)}%" if ram_util else ""
        ram_low = ram_util and ram_util < 10

        note = ""
        if state not in ("C", "F"):
            if (
                not short_run
                and cpupercent is not None
                and ncpus_used
                and cpupercent < ncpus_used * 10
            ):
                note = "❗ <10% of CPU used"
        else:
            if used_s < 60:
                note = "short"
            elif cpu_low and ram_low:
                note = "<10% CPU, <10% RAM"
            elif cpu_low:
                note = "<10% CPU"
            elif ram_low:
                note = "<10% RAM"
            if job.get("exit_status", 0) != 0:
                note = "!" + note

        cpu_field = (
            mqstat.Colors.RED + cpu_util_str + mqstat.Colors.ENDC
            if cpu_low and not short_run
            else cpu_util_str
        )
        ram_field = (
            mqstat.Colors.RED + ram_util_str + mqstat.Colors.ENDC
            if ram_low and not short_run
            else ram_util_str
        )

        row_color = ""
        if state == "Q":
            row_color = mqstat.Colors.YELLOW
        elif state in ("C", "F"):
            row_color = (
                mqstat.Colors.GREEN
                if job.get("exit_status", 0) == 0
                else mqstat.Colors.RED
            )
        elif state != "R":
            row_color = ORANGE

        rows.append(
            {
                "job_id": job_id,
                "name": name,
                "used": used,
                "bar": bar,
                "wall": total,
                "waited": waited,
                "age": age,
                "cpu": str(cpu),
                "cpu_util": cpu_field,
                "ram": str(ram),
                "ram_util": ram_field,
                "state": state,
                "queue": queue,
                "note": note,
                "source": job.get("source", ""),
                "raw": job,
                "row_color": row_color,
            }
        )

    if not rows:
        return ["  ".join(headers)], []

    id_w = max(len(headers[0]), max(visible_len(r["job_id"]) for r in rows))
    time_w = len(headers[2])
    wall_w = max(len(headers[4]), max(visible_len(r["wall"]) for r in rows))
    wait_w = max(len(headers[5]), max(visible_len(r["waited"]) for r in rows))
    age_w = max(len(headers[6]), max(visible_len(r["age"]) for r in rows))
    cpu_w = max(len(headers[7]), max(visible_len(r["cpu"]) for r in rows))
    cpuu_w = max(len(headers[8]), max(visible_len(r["cpu_util"]) for r in rows))
    ram_w = max(len(headers[9]), max(visible_len(r["ram"]) for r in rows))
    ramu_w = max(len(headers[10]), max(visible_len(r["ram_util"]) for r in rows))
    state_w = max(len(headers[11]), max(visible_len(r["state"]) for r in rows))
    queue_w = max(len(headers[12]), max(visible_len(r["queue"]) for r in rows))
    note_w = max(len(headers[13]), max(visible_len(r["note"]) for r in rows))
    source_w = max(len(headers[14]), max(visible_len(r["source"]) for r in rows))
    name_w_candidate = max(len(headers[1]), max(visible_len(r["name"]) for r in rows))
    other_w = (
        id_w
        + time_w
        + 20
        + wall_w
        + wait_w
        + age_w
        + cpu_w
        + cpuu_w
        + ram_w
        + ramu_w
        + state_w
        + queue_w
        + note_w
        + source_w
        + 2 * (len(headers) - 1)
    )
    min_name_w = len("add_otus_to_backend_db.84.sh") * 2
    max_name_w = min_name_w
    if maxx > other_w + min_name_w:
        max_name_w = maxx - other_w
    name_w = min(name_w_candidate, max_name_w)

    header_parts = [
        headers[0].ljust(id_w),
        headers[1].ljust(name_w),
        headers[2].ljust(time_w),
        headers[3].ljust(20),
        headers[4].ljust(wall_w),
        headers[5].ljust(wait_w),
        headers[6].ljust(age_w),
        headers[7].rjust(cpu_w),
        headers[8].rjust(cpuu_w),
        headers[9].rjust(ram_w),
        headers[10].rjust(ramu_w),
        headers[11].ljust(state_w),
        headers[12].ljust(queue_w),
        headers[13].ljust(note_w),
        headers[14].ljust(source_w),
    ]
    lines = ["  ".join(header_parts)]

    for r in rows:
        parts = [
            ljust_ansi(r["job_id"], id_w),
            ljust_ansi(r["name"], name_w),
            ljust_ansi(r["used"], time_w),
            r["bar"],
            ljust_ansi(r["wall"], wall_w),
            ljust_ansi(r["waited"], wait_w),
            ljust_ansi(r["age"], age_w),
            rjust_ansi(r["cpu"], cpu_w),
            rjust_ansi(r["cpu_util"], cpuu_w),
            rjust_ansi(r["ram"], ram_w),
            rjust_ansi(r["ram_util"], ramu_w),
            ljust_ansi(r["state"], state_w),
            ljust_ansi(r["queue"], queue_w),
            ljust_ansi(r["note"], note_w),
            ljust_ansi(r["source"], source_w),
        ]
        coloured_parts = []
        row_colour = r.get("row_color", "")
        for idx, part in enumerate(parts):
            if idx == 3:  # progress column
                coloured_parts.append(part)
            elif row_colour and not ansi_re.search(part):
                coloured_parts.append(row_colour + part + mqstat.Colors.ENDC)
            else:
                coloured_parts.append(part)
        lines.append("  ".join(coloured_parts))

    jobs_out = [r["raw"] for r in rows]
    return lines, jobs_out


def main() -> None:
    parser = argparse.ArgumentParser(description="Interactive job viewer")
    parser.add_argument(
        "--qstat-json",
        help="Path to qstat.json",
        default="/pkg/hpc/scripts/qstat.json",
    )
    parser.add_argument(
        "--qstatx-json",
        help="Path to qstatx.json",
        default="/pkg/hpc/scripts/qstatx.json",
    )
    parser.add_argument(
        "--print-first-page",
        action="store_true",
        help="Print first page of job table to stdout and exit",
    )
    parser.add_argument(
        "--profile",
        metavar="FILE",
        help="Write cProfile stats to FILE",
    )
    args = parser.parse_args()

    user = getpass.getuser()

    profiler = None
    if args.profile:
        import cProfile

        profiler = cProfile.Profile()
        profiler.enable()

    def get_jobs(include_history: bool = False):
        active = _load_jobs_from_json(args.qstat_json, user, "qstat.json")
        job_dict = {j["id"]: j for j in active}
        if include_history and len(job_dict) <= MAX_JOBS:
            hist = _load_jobs_from_json(args.qstatx_json, user, "qstatx.json")
            for job in hist:
                if len(job_dict) >= MAX_JOBS:
                    break
                if job["id"] in job_dict:
                    continue
                if job.get("state") not in ("C", "F"):
                    updated = _fetch_job(job["id"], user)
                    if updated:
                        updated["source"] = job["source"]
                        job = updated
                job_dict[job["id"]] = job
            if len(job_dict) < MAX_JOBS:
                recent, total, updated_count = _recent_finished_jobs(user, set(job_dict))
                if total:
                    print(
                        f"qselect detected {total} jobs; updated {updated_count}",
                        file=sys.stderr,
                    )
                for job in recent:
                    if len(job_dict) >= MAX_JOBS:
                        break
                    job_dict.setdefault(job["id"], job)
        return list(job_dict.values())

    if args.print_first_page:
        jobs = get_jobs(include_history=True)
        now = time.time()
        finished = {}
        running = []
        queued = []
        for job in jobs:
            if job.get("queue") == "cpu_inter_exec":
                continue
            state = job.get("state")
            if state in ("C", "F"):
                finished[job["id"]] = job
            elif state == "Q":
                queued.append(job)
            else:
                running.append(job)
        if running or queued:
            for jid, job in list(finished.items()):
                ft = job.get("obittime") or job.get("mtime", now)
                if now - ft > 24 * 3600:
                    finished.pop(jid, None)
        running.sort(key=lambda j: j.get("walltime_used", 0), reverse=True)
        queued.sort(key=lambda j: now - j.get("qtime", now), reverse=True)
        finished_jobs = sorted(
            finished.values(), key=lambda j: j.get("obittime") or j.get("mtime", 0), reverse=True
        )
        all_jobs = running + queued + finished_jobs
        if len(all_jobs) > MAX_JOBS:
            print(
                f"More than {MAX_JOBS} jobs; showing first {MAX_JOBS}.",
                file=sys.stderr,
            )
            all_jobs = all_jobs[:MAX_JOBS]
        lines, _ = format_jobs(all_jobs, shutil.get_terminal_size().columns, now=now)
        for line in lines[:24]:
            print(line)
        if profiler:
            profiler.disable()
            profiler.dump_stats(args.profile)
        return

    def _draw(stdscr):
        curses.curs_set(0)
        curses.start_color()
        curses.use_default_colors()
        curses.init_pair(1, curses.COLOR_GREEN, -1)
        curses.init_pair(2, curses.COLOR_RED, -1)
        curses.init_pair(3, curses.COLOR_YELLOW, -1)
        if getattr(curses, "COLORS", 8) > 208:
            try:
                curses.init_pair(4, 208, -1)  # orange if terminal supports it
            except (curses.error, ValueError):
                curses.init_pair(4, curses.COLOR_YELLOW, -1)
        else:
            curses.init_pair(4, curses.COLOR_YELLOW, -1)
        stdscr.nodelay(True)
        stdscr.keypad(True)
        curses.mousemask(
            curses.BUTTON1_CLICKED
            | curses.BUTTON4_PRESSED
            | curses.BUTTON5_PRESSED
        )

        finished = {}
        selected = 1  # absolute selected row index (1..)
        offset = 0  # topmost job line displayed (0-based)
        x_offset = 0
        lines, job_rows = [], []
        max_line_width = 0
        refresh = True
        show_queued = True
        last_refresh = 0.0
        user_warning = None
        user_warn_until = 0.0
        fetch_history = False
        running = []
        queued = []
        history_thread = None
        history_result: dict[str, dict] = {}

        while True:
            maxy, maxx = stdscr.getmaxyx()
            max_off = max(0, max_line_width - maxx + 1)
            x_offset = min(x_offset, max_off)
            key = stdscr.getch()
            if user_warning and time.time() > user_warn_until:
                user_warning = None
            if refresh_due(last_refresh):
                refresh = True

            if key == ord("q"):
                break
            elif key == curses.KEY_MOUSE:
                try:
                    _, _, my, _, bstate = curses.getmouse()
                except curses.error:
                    pass
                else:
                    if bstate & curses.BUTTON1_CLICKED:
                        if 1 <= my < min(len(lines), maxy - 1):
                            selected = min(offset + my, len(lines) - 1)
                    elif bstate & curses.BUTTON4_PRESSED:
                        if lines:
                            selected = max(1, selected - 1)
                    elif bstate & curses.BUTTON5_PRESSED:
                        if lines:
                            selected = min(selected + 1, len(lines) - 1)
            elif key == curses.KEY_RIGHT:
                if lines:
                    x_offset = min(x_offset + 8, max(0, max_line_width - maxx + 1))
            elif key == curses.KEY_LEFT:
                if lines:
                    x_offset = max(x_offset - 8, 0)
            elif key == curses.KEY_DOWN:
                if lines:
                    selected = min(selected + 1, len(lines) - 1)
            elif key == curses.KEY_UP:
                if lines:
                    selected = max(1, selected - 1)
            elif key == curses.KEY_NPAGE:
                if lines:
                    page = maxy - 2
                    selected = min(len(lines) - 1, selected + page)
            elif key == curses.KEY_PPAGE:
                if lines:
                    page = maxy - 2
                    selected = max(1, selected - page)
            elif key == curses.KEY_HOME:
                selected = 1
                offset = 0
            elif key in (ord("o"), ord("e")):
                if 0 < selected <= len(job_rows):
                    job = job_rows[selected - 1]
                    which = "e" if key == ord("e") else "o"
                    cmd, use_shell = _view_log_command(job, which, user)
                    if cmd:
                        curses.endwin()
                        subprocess.call(cmd, shell=use_shell)
                        stdscr.clear()
                        curses.curs_set(0)
            elif key == ord("f"):
                if 0 < selected <= len(job_rows):
                    job = job_rows[selected - 1]
                    cmd = f"qstat -xf {job['id']} | less"
                    curses.endwin()
                    subprocess.call(cmd, shell=True)
                    stdscr.clear()
                    curses.curs_set(0)
            elif key == ord("s"):
                if 0 < selected <= len(job_rows):
                    job = job_rows[selected - 1]
                    if job.get("state") == "R":
                        curses.endwin()
                        subprocess.call(["/pkg/hpc/scripts/ssh-to-job", str(job["id"])])
                        stdscr.clear()
                        curses.curs_set(0)
                    else:
                        user_warning = "Job is not running"
                        user_warn_until = time.time() + 2
                else:
                    user_warning = "No job selected"
                    user_warn_until = time.time() + 2
            elif key == ord("g"):
                if 0 < selected <= len(job_rows):
                    job = job_rows[selected - 1]
                    url = grafana_url(job.get("id"))
                    curses.endwin()
                    print(url)
                    input("Press Enter to return...")
                    stdscr.clear()
                    curses.curs_set(0)
            elif key == ord("k"):
                if 0 < selected <= len(job_rows):
                    job = job_rows[selected - 1]
                    curses.endwin()
                    subprocess.call(["qdel", str(job["id"])])
                    stdscr.clear()
                    curses.curs_set(0)
                    user_warning = f"qdel {job['id']} sent"
                    user_warn_until = time.time() + 2
                    refresh = True
                else:
                    user_warning = "No job selected"
                    user_warn_until = time.time() + 2
            elif key == ord("/"):
                curses.echo()
                stdscr.nodelay(False)
                stdscr.move(maxy - 1, 0)
                stdscr.clrtoeol()
                stdscr.addstr(maxy - 1, 0, "/")
                try:
                    query = stdscr.getstr(maxy - 1, 1).decode()
                except Exception:
                    query = ""
                stdscr.nodelay(True)
                curses.noecho()
                if query:
                    ql = query.lower()
                    for idx, job in enumerate(job_rows, start=1):
                        if ql in job.get("name", "").lower() or ql in str(job.get("id", "")).lower():
                            selected = idx
                            break
            elif key == ord("r"):
                refresh = True
            elif key == ord("u"):
                show_queued = not show_queued
                refresh = True
            elif key == ord("h"):
                show_help(stdscr)
                refresh = True
            elif key not in (-1, curses.KEY_MOUSE, curses.KEY_RESIZE):
                if 32 <= key <= 126:
                    user_warning = f"Unknown key '{chr(key)}'"
                else:
                    user_warning = "Unknown key"
                user_warn_until = time.time() + 2

            if refresh:
                jobs = _load_jobs_from_json(args.qstat_json, user, "qstat.json")
                now = time.time()
                running = []
                queued = []
                for job in jobs:
                    if job.get("queue") == "cpu_inter_exec":
                        continue
                    state = job.get("state")
                    if state in ("C", "F"):
                        finished[job["id"]] = job
                    elif state == "Q":
                        queued.append(job)
                    else:
                        running.append(job)
                if running or queued:
                    for jid, job in list(finished.items()):
                        ft = job.get("obittime") or job.get("mtime", now)
                        if now - ft > 24 * 3600:
                            finished.pop(jid, None)
                for jid, job in list(finished.items()):
                    if job.get("queue") == "cpu_inter_exec":
                        finished.pop(jid, None)

                running.sort(key=lambda j: j.get("walltime_used", 0), reverse=True)
                queued.sort(key=lambda j: now - j.get("qtime", now), reverse=True)
                active_jobs = running + (queued if show_queued else [])
                if len(active_jobs) > MAX_JOBS:
                    user_warning = (
                        f"More than {MAX_JOBS} running/queued jobs; showing first {MAX_JOBS}. Finished jobs skipped."
                    )
                    user_warn_until = time.time() + 5
                    active_jobs = active_jobs[:MAX_JOBS]
                    fetch_history = False
                    history_thread = None
                else:
                    user_warning = "Loading finished jobs..."
                    user_warn_until = float("inf")
                    existing = {j["id"] for j in active_jobs} | set(finished)
                    history_thread, history_result = _start_history_loader(
                        args.qstatx_json, user, existing
                    )
                    fetch_history = True
                lines, job_rows = format_jobs(active_jobs, maxx, now=now)
                max_line_width = max((visible_len(l) for l in lines), default=0)
                last_refresh = time.time()
                refresh = False
            elif fetch_history:
                if history_thread and not history_thread.is_alive():
                    finished.update(history_result)
                    history_result = {}
                    finished_jobs = sorted(
                        finished.values(),
                        key=lambda j: j.get("obittime") or j.get("mtime", 0),
                        reverse=True,
                    )
                    all_jobs = running + (queued if show_queued else []) + finished_jobs
                    if len(all_jobs) > MAX_JOBS:
                        user_warning = f"More than {MAX_JOBS} jobs; showing first {MAX_JOBS}."
                        user_warn_until = time.time() + 5
                        all_jobs = all_jobs[:MAX_JOBS]
                    else:
                        user_warning = None
                        user_warn_until = 0
                    now = time.time()
                    lines, job_rows = format_jobs(all_jobs, maxx, now=now)
                    max_line_width = max((visible_len(l) for l in lines), default=0)
                    fetch_history = False
                    history_thread = None
                    last_refresh = time.time()

            stdscr.erase()
            warning = None
            page = maxy - 3
            if lines:
                max_sel = len(lines) - 1
                selected = min(max(1, selected), max_sel)
                vis_rows = page - (1 if warning else 0)
                offset = max(0, min(offset, max_sel - vis_rows))
                if selected < offset + 1:
                    offset = selected - 1
                elif selected > offset + vis_rows:
                    offset = selected - vis_rows
                y = 0
                if warning:
                    draw_line(stdscr, 0, warning, maxx)
                    y = 1
                draw_line(stdscr, y, lines[0], maxx, highlight=True, x_offset=x_offset)
                visible = lines[1 + offset : 1 + offset + vis_rows]
                for i, line in enumerate(visible, start=y + 1):
                    draw_line(
                        stdscr,
                        i,
                        line,
                        maxx,
                        highlight=(offset + i - y == selected),
                        x_offset=x_offset,
                    )
            else:
                offset = 0
                selected = 1
            if user_warning:
                addstr_safe(stdscr, maxy - 2, 0, user_warning, maxx, curses.color_pair(2))
            help_text = (
                "q quit  h help  / search  o stdout  e stderr  f full  s ssh  r refresh  u toggle queued  g grafana  k kill"
            )
            addstr_safe(stdscr, maxy - 1, 0, help_text, maxx, curses.A_REVERSE)
            stdscr.refresh()
            if key == -1:
                time.sleep(0.1)

    curses.wrapper(_draw)

    if profiler:
        profiler.disable()
        profiler.dump_stats(args.profile)


if __name__ == "__main__":
    main()
